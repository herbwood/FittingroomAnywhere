{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThQ9ZujjX-xD"
   },
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23559,
     "status": "ok",
     "timestamp": 1566525621544,
     "user": {
      "displayName": "Jaehun Hwang",
      "photoUrl": "",
      "userId": "00170005484941026663"
     },
     "user_tz": -540
    },
    "id": "AddndrO8XdW1",
    "outputId": "4a41888e-2612-406d-d14e-6ffb955fda50"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCo9fSfZXcwB"
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YdqNG-9eaba"
   },
   "outputs": [],
   "source": [
    "# !pip install pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scipy < 1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy==1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JiQHHh6LBKSu"
   },
   "source": [
    "### Check GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9881,
     "status": "ok",
     "timestamp": 1566525633584,
     "user": {
      "displayName": "Jaehun Hwang",
      "photoUrl": "",
      "userId": "00170005484941026663"
     },
     "user_tz": -540
    },
    "id": "P1tq6g1DBQv9",
    "outputId": "c25a1265-7fda-488f-ddb7-496a51577c57"
   },
   "outputs": [],
   "source": [
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "# !pip install psutil # already installed\n",
    "# !pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 884,
     "status": "ok",
     "timestamp": 1566537357774,
     "user": {
      "displayName": "Jaehun Hwang",
      "photoUrl": "",
      "userId": "00170005484941026663"
     },
     "user_tz": -540
    },
    "id": "HDDtHurtBOHd",
    "outputId": "440f7e15-0599-4600-cb30-4d3202196203"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def printm():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "    \n",
    "printm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFWV_kAbXG5a"
   },
   "source": [
    "## Imort plotCSVfile.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "#from operator import add\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import butter, lfilter, freqz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def plotResultfromCSV(datetime, point_gap=1):\n",
    "    DA_losses = []\n",
    "    DB_losses = []\n",
    "    gA_d_losses_synthetic = []\n",
    "    gB_d_losses_synthetic = []\n",
    "    gA_losses_reconstructed = []\n",
    "    gB_losses_reconstructed = []\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    reconstruction_losses = []\n",
    "\n",
    "    with open('images/{}/loss_output.csv'.format(datetime), newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            DA_losses.append(float(row['DA_losses']))\n",
    "            DB_losses.append(float(row['DB_losses']))\n",
    "            gA_d_losses_synthetic.append(float(row['gA_d_losses_synthetic']))\n",
    "            gB_d_losses_synthetic.append(float(row['gB_d_losses_synthetic']))\n",
    "            gA_losses_reconstructed.append(float(row['gA_losses_reconstructed']))\n",
    "            gB_losses_reconstructed.append(float(row['gB_losses_reconstructed']))\n",
    "            D_losses.append(float(row['D_losses']))\n",
    "            reconstruction_losses.append(float(row['reconstruction_losses']))\n",
    "            G_loss = row['G_losses']\n",
    "            if G_loss[0] == '[':\n",
    "                G_loss = G_loss.split(',')[0][1:]\n",
    "            G_losses.append(float(G_loss))\n",
    "        csvfile.close()\n",
    "\n",
    "        # Calculate interesting things to plot\n",
    "        DA_losses = np.array(DA_losses)\n",
    "        DB_losses = np.array(DB_losses)\n",
    "        GA_losses = np.add(np.array(gA_d_losses_synthetic), np.array(gA_losses_reconstructed))\n",
    "        GB_losses = np.add(np.array(gB_d_losses_synthetic), np.array(gB_losses_reconstructed))\n",
    "        RA_losses = np.array(gA_losses_reconstructed)\n",
    "        RB_losses = np.array(gB_losses_reconstructed)\n",
    "\n",
    "        G_losses = np.array(G_losses)\n",
    "        D_losses = np.array(D_losses)\n",
    "        reconstruction_losses = np.add(np.array(gA_losses_reconstructed), np.array(gB_losses_reconstructed))\n",
    "\n",
    "    points = range(0, len(G_losses), point_gap)\n",
    "    fs = 1000\n",
    "    cutoff = 2\n",
    "    order = 6\n",
    "\n",
    "    # Lowpass filter\n",
    "    GA = butter_lowpass_filter(GA_losses[points], cutoff, fs, order)\n",
    "    GB = butter_lowpass_filter(GB_losses[points], cutoff, fs, order)\n",
    "\n",
    "    DA = butter_lowpass_filter(DA_losses[points], cutoff, fs, order)\n",
    "    DB = butter_lowpass_filter(DB_losses[points], cutoff, fs, order)\n",
    "\n",
    "    RA = butter_lowpass_filter(RA_losses[points], cutoff, fs, order)\n",
    "    RB = butter_lowpass_filter(RB_losses[points], cutoff, fs, order)\n",
    "\n",
    "    G = butter_lowpass_filter(G_losses[points], cutoff, fs, order)\n",
    "    D = butter_lowpass_filter(D_losses[points], cutoff, fs, order)\n",
    "    R = butter_lowpass_filter(reconstruction_losses[points], cutoff, fs, order)\n",
    "\n",
    "    fig_D = plt.figure(1)\n",
    "    plt.plot(GA, label='GB_losses')\n",
    "    plt.plot(GB, label='GA_losses')\n",
    "    plt.ylabel('Generator losses')\n",
    "    plt.legend()\n",
    "\n",
    "    fig_G = plt.figure(2)\n",
    "    plt.plot(DA, label='DA_losses')\n",
    "    plt.plot(DB, label='DB_losses')\n",
    "    plt.ylabel('Discriminator losses')\n",
    "    plt.legend()\n",
    "\n",
    "    fig_recons = plt.figure(3)\n",
    "    plt.plot(RA, label='Reconstruction_loss_A')\n",
    "    plt.plot(RB, label='Reconstruction_loss_B')\n",
    "    plt.ylabel('Reconstruction losses')\n",
    "    plt.legend()\n",
    "\n",
    "    fig_tots = plt.figure(4)\n",
    "    plt.plot(G, label='G_losses')\n",
    "    plt.plot(D, label='D_losses')\n",
    "    plt.plot(R, label='Reconstruction_losses')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plots\n",
    "    fig_D.show()\n",
    "    fig_G.show()\n",
    "    fig_recons.show()\n",
    "    fig_tots.show()\n",
    "\n",
    "    plt.pause(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    datetime = str(sys.argv[1])\n",
    "    points = int(sys.argv[2])\n",
    "    plotResultfromCSV(datetime, points)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.utils import Sequence\n",
    "#from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(nr_of_channels, batch_size=1, nr_A_train_imgs=None, nr_B_train_imgs=None,\n",
    "              nr_A_test_imgs=None, nr_B_test_imgs=None, project_dir = '', subfolder='',\n",
    "              generator=False, D_model=None, use_multiscale_discriminator=False, use_supervised_learning=False, REAL_LABEL=1.0):\n",
    "\n",
    "    trainA_path = os.path.join(project_dir, 'datasets', subfolder, 'trainA')\n",
    "    trainB_path = os.path.join(project_dir, 'datasets', subfolder, 'trainB')\n",
    "    testA_path = os.path.join(project_dir, 'datasets', subfolder, 'testA')\n",
    "    testB_path = os.path.join(project_dir, 'datasets', subfolder, 'testB')\n",
    "\n",
    "    trainA_image_names = os.listdir(trainA_path)\n",
    "#     print(trainA_image_names[:20])\n",
    "    if nr_A_train_imgs != None:\n",
    "        trainA_image_names = trainA_image_names[:nr_A_train_imgs]\n",
    "\n",
    "    trainB_image_names = os.listdir(trainB_path)\n",
    "    if nr_B_train_imgs != None:\n",
    "        trainB_image_names = trainB_image_names[:nr_B_train_imgs]\n",
    "\n",
    "    testA_image_names = os.listdir(testA_path)\n",
    "    if nr_A_test_imgs != None:\n",
    "        testA_image_names = testA_image_names[:nr_A_test_imgs]\n",
    "\n",
    "    testB_image_names = os.listdir(testB_path)\n",
    "    if nr_B_test_imgs != None:\n",
    "        testB_image_names = testB_image_names[:nr_B_test_imgs]\n",
    "\n",
    "    if generator:\n",
    "        return data_sequence(trainA_path, trainB_path, trainA_image_names, trainB_image_names, batch_size=batch_size)  # D_model, use_multiscale_discriminator, use_supervised_learning, REAL_LABEL)\n",
    "    else:\n",
    "        trainA_images = create_image_array(trainA_image_names, trainA_path, nr_of_channels)\n",
    "        print(f\"trainA dataset shape: {trainA_images.shape}\")\n",
    "        trainB_images = create_image_array(trainB_image_names, trainB_path, nr_of_channels)\n",
    "        print(f\"trainB dataset shape: {trainB_images.shape}\")\n",
    "        testA_images = create_image_array(testA_image_names, testA_path, nr_of_channels)\n",
    "        print(f\"testA dataset shape: {testA_images.shape}\")\n",
    "        testB_images = create_image_array(testB_image_names, testB_path, nr_of_channels)\n",
    "        print(f\"testB dataset shape: {testB_images.shape}\")\n",
    "        return {\"trainA_images\": trainA_images, \"trainB_images\": trainB_images,\n",
    "                \"testA_images\": testA_images, \"testB_images\": testB_images,\n",
    "                \"trainA_image_names\": trainA_image_names,\n",
    "                \"trainB_image_names\": trainB_image_names,\n",
    "                \"testA_image_names\": testA_image_names,\n",
    "                \"testB_image_names\": testB_image_names}\n",
    "\n",
    "\n",
    "def create_image_array(image_list, image_path, nr_of_channels):\n",
    "    image_array = []\n",
    "    for image_name in image_list:\n",
    "        if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
    "            if nr_of_channels == 1:  # Gray scale image -> MR image\n",
    "                image = Image.open(os.path.join(image_path, image_name))\n",
    "                image = np.array(image)\n",
    "                image = image[:, :, np.newaxis]\n",
    "            else:                   # RGB image -> street view\n",
    "                image = Image.open(os.path.join(image_path, image_name))\n",
    "                image = np.array(image)\n",
    "            image = normalize_array(image)\n",
    "            image_array.append(image)\n",
    "\n",
    "    return np.array(image_array)\n",
    "\n",
    "# If using 16 bit depth images, use the formula 'array = array / 32767.5 - 1' instead\n",
    "def normalize_array(array):\n",
    "    array = np.subtract(np.divide(array, 127.5), 1.)\n",
    "    return array\n",
    "\n",
    "\n",
    "class data_sequence(Sequence):\n",
    "\n",
    "    def __init__(self, trainA_path, trainB_path, image_list_A, image_list_B, batch_size=1):  # , D_model, use_multiscale_discriminator, use_supervised_learning, REAL_LABEL):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_A = []\n",
    "        self.train_B = []\n",
    "        for image_name in image_list_A:\n",
    "            if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
    "                self.train_A.append(os.path.join(trainA_path, image_name))\n",
    "        for image_name in image_list_B:\n",
    "            if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
    "                self.train_B.append(os.path.join(trainB_path, image_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(max(len(self.train_A), len(self.train_B)) / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):  # , use_multiscale_discriminator, use_supervised_learning):if loop_index + batch_size >= min_nr_imgs:\n",
    "        if idx >= min(len(self.train_A), len(self.train_B)):\n",
    "            # If all images soon are used for one domain,\n",
    "            # randomly pick from this domain\n",
    "            if len(self.train_A) <= len(self.train_B):\n",
    "                indexes_A = np.random.randint(len(self.train_A), size=self.batch_size)\n",
    "                batch_A = []\n",
    "                for i in indexes_A:\n",
    "                    batch_A.append(self.train_A[i])\n",
    "                batch_B = self.train_B[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            else:\n",
    "                indexes_B = np.random.randint(len(self.train_B), size=self.batch_size)\n",
    "                batch_B = []\n",
    "                for i in indexes_B:\n",
    "                    batch_B.append(self.train_B[i])\n",
    "                batch_A = self.train_A[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        else:\n",
    "            batch_A = self.train_A[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_B = self.train_B[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        real_images_A = create_image_array(batch_A, '', 3)\n",
    "        real_images_B = create_image_array(batch_B, '', 3)\n",
    "\n",
    "        return real_images_A, real_images_B  # input_data, target_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Input, Conv2D, Activation, add, BatchNormalization, UpSampling2D, ZeroPadding2D, Conv2DTranspose, Flatten, MaxPooling2D, AveragePooling2D\n",
    "# from keras_contrib.layers.normalization import InstanceNormalization, InputSpec\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.engine import InputSpec\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import mean\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.utils import plot_model\n",
    "from keras.engine.topology import Network\n",
    "\n",
    "from collections import OrderedDict\n",
    "from scipy.misc import imsave, toimage  # has depricated\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# sys.path.append('../')\n",
    "# import load_data\n",
    "\n",
    "np.random.seed(seed=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self, lr_D=2e-4, lr_G=2e-4, image_shape=(256*1, 256*1, 3),\n",
    "                 date_time_string_addition='_test', project_dir = '.', image_folder='', to_train=True, to_restore=False):\n",
    "        # check if training or testing the results\n",
    "        self.to_train = to_train\n",
    "        self.to_restore = to_restore\n",
    "        self.project_dir = project_dir\n",
    "\n",
    "        self.img_shape = image_shape\n",
    "        self.channels = self.img_shape[-1]\n",
    "        self.normalization = InstanceNormalization\n",
    "        # Hyper parameters\n",
    "        self.lambda_1 = 10.0  # Cyclic loss weight A_2_B\n",
    "        self.lambda_2 = 10.0  # Cyclic loss weight B_2_A\n",
    "        self.lambda_D = 1.0  # Weight for loss from discriminator guess on synthetic images\n",
    "        self.learning_rate_D = lr_D\n",
    "        self.learning_rate_G = lr_G\n",
    "        self.generator_iterations = 1  # Number of generator training iterations in each training loop\n",
    "        self.discriminator_iterations = 1  # Number of generator training iterations in each training loop\n",
    "        self.beta_1 = 0.5\n",
    "        self.beta_2 = 0.999\n",
    "        self.batch_size = 1\n",
    "        self.epochs = 200  # choose multiples of 25 since the models are save each 25th epoch\n",
    "        self.save_interval = 1\n",
    "        self.synthetic_pool_size = 50\n",
    "\n",
    "        # Linear decay of learning rate, for both discriminators and generators\n",
    "        self.use_linear_decay = True\n",
    "        self.decay_epoch = 101  # The epoch where the linear decay of the learning rates start\n",
    "\n",
    "        # Identity loss - sometimes send images from B to G_A2B (and the opposite) to teach identity mappings\n",
    "        self.use_identity_learning = True\n",
    "        self.identity_mapping_modulus = 10  # Identity mapping will be done each time the iteration number is divisable with this number\n",
    "\n",
    "        # PatchGAN - if false the discriminator learning rate should be decreased\n",
    "        self.use_patchgan = True\n",
    "\n",
    "        # Resize convolution - instead of transpose convolution in deconvolution layers (uk) - can reduce checkerboard artifacts but the blurring might affect the cycle-consistency\n",
    "        self.use_resize_convolution = False\n",
    "\n",
    "        # Supervised learning part - for MR images - comparison\n",
    "        self.use_supervised_learning = False\n",
    "        self.supervised_weight = 10.0\n",
    "\n",
    "        # Fetch data during training instead of pre caching all images - might be necessary for large datasets\n",
    "        self.use_data_generator = False\n",
    "\n",
    "        # Tweaks\n",
    "        self.REAL_LABEL = 1.0  # Use e.g. 0.9 to avoid training the discriminators to zero loss\n",
    "\n",
    "        # Used as storage folder name\n",
    "        self.date_time = time.strftime('%Y%m%d-%H%M%S', time.localtime()) + date_time_string_addition\n",
    "\n",
    "        # optimizer\n",
    "        self.opt_D = Adam(self.learning_rate_D, self.beta_1, self.beta_2)\n",
    "        self.opt_G = Adam(self.learning_rate_G, self.beta_1, self.beta_2)\n",
    "\n",
    "        # ======= Discriminator model ==========\n",
    "        D_A = self.modelDiscriminator()\n",
    "        D_B = self.modelDiscriminator()\n",
    "        loss_weights_D = [0.5]  # 0.5 since we train on real and synthetic images\n",
    "        # D_A.summary()\n",
    "\n",
    "        # Discriminator builds\n",
    "        image_A = Input(shape=self.img_shape)\n",
    "        image_B = Input(shape=self.img_shape)\n",
    "        guess_A = D_A(image_A)\n",
    "        guess_B = D_B(image_B)\n",
    "        self.D_A = Model(inputs=image_A, outputs=guess_A, name='D_A_model')\n",
    "        self.D_B = Model(inputs=image_B, outputs=guess_B, name='D_B_model')\n",
    "\n",
    "        # self.D_A.summary()\n",
    "        # self.D_B.summary()\n",
    "        self.D_A.compile(optimizer=self.opt_D,\n",
    "                         loss=self.lse,\n",
    "                         loss_weights=loss_weights_D)\n",
    "        self.D_B.compile(optimizer=self.opt_D,\n",
    "                         loss=self.lse,\n",
    "                         loss_weights=loss_weights_D)\n",
    "\n",
    "        # Use Networks to avoid falsy keras error about weight descripancies\n",
    "        self.D_A_static = Network(inputs=image_A, outputs=guess_A, name='D_A_static_model')\n",
    "        self.D_B_static = Network(inputs=image_B, outputs=guess_B, name='D_B_static_model')\n",
    "\n",
    "        # ======= Generator model ==========\n",
    "        # Do note update discriminator weights during generator training\n",
    "        self.D_A_static.trainable = False\n",
    "        self.D_B_static.trainable = False\n",
    "\n",
    "        # Generators\n",
    "        self.G_A2B = self.modelGenerator(name='G_A2B_model')\n",
    "        self.G_B2A = self.modelGenerator(name='G_B2A_model')\n",
    "        # self.G_A2B.summary()\n",
    "\n",
    "        if self.use_identity_learning:\n",
    "            self.G_A2B.compile(optimizer=self.opt_G, loss='MAE')\n",
    "            self.G_B2A.compile(optimizer=self.opt_G, loss='MAE')\n",
    "\n",
    "        # Generator builds\n",
    "        real_A = Input(shape=self.img_shape, name='real_A')\n",
    "        real_B = Input(shape=self.img_shape, name='real_B')\n",
    "        synthetic_B = self.G_A2B(real_A) # fake B\n",
    "        synthetic_A = self.G_B2A(real_B) # fake A\n",
    "        dA_guess_synthetic = self.D_A_static(synthetic_A) # fake A score\n",
    "        dB_guess_synthetic = self.D_B_static(synthetic_B) # fake B score\n",
    "        reconstructed_A = self.G_B2A(synthetic_B) # cycle A\n",
    "        reconstructed_B = self.G_A2B(synthetic_A) # cycle B\n",
    "\n",
    "        model_outputs = [reconstructed_A, reconstructed_B]\n",
    "        compile_losses = [self.cycle_loss, self.cycle_loss,\n",
    "                          self.lse, self.lse]\n",
    "        compile_weights = [self.lambda_1, self.lambda_2,\n",
    "                           self.lambda_D, self.lambda_D]\n",
    "\n",
    "        model_outputs.append(dA_guess_synthetic)\n",
    "        model_outputs.append(dB_guess_synthetic)\n",
    "\n",
    "        if self.use_supervised_learning:\n",
    "            model_outputs.append(synthetic_A)\n",
    "            model_outputs.append(synthetic_B)\n",
    "            compile_losses.append('MAE')\n",
    "            compile_losses.append('MAE')\n",
    "            compile_weights.append(self.supervised_weight)\n",
    "            compile_weights.append(self.supervised_weight)\n",
    "\n",
    "        self.G_model = Model(inputs=[real_A, real_B],\n",
    "                             outputs=model_outputs,\n",
    "                             name='G_model')\n",
    "\n",
    "        self.G_model.compile(optimizer=self.opt_G,\n",
    "                             loss=compile_losses,\n",
    "                             loss_weights=compile_weights)\n",
    "        # self.G_A2B.summary()\n",
    "\n",
    "        # ======= Data ==========\n",
    "        # Use 'None' to fetch all available images\n",
    "        nr_A_train_imgs = None\n",
    "        nr_B_train_imgs = None\n",
    "        nr_A_test_imgs = None\n",
    "        nr_B_test_imgs = None\n",
    "\n",
    "        if self.use_data_generator:\n",
    "            print('--- Using dataloader during training ---')\n",
    "        else:\n",
    "            print('--- Caching data ---')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if self.use_data_generator:            \n",
    "            self.data_generator = load_data(\n",
    "                nr_of_channels=self.channels, batch_size=self.batch_size, generator=True, \n",
    "                project_dir=self.project_dir, subfolder=image_folder)\n",
    "\n",
    "            # Only store test images\n",
    "            nr_A_train_imgs = 0\n",
    "            nr_B_train_imgs = 0\n",
    "\n",
    "        data = load_data(nr_of_channels=self.channels, # 3\n",
    "                                   batch_size=self.batch_size, # 1\n",
    "                                   nr_A_train_imgs=nr_A_train_imgs, # None\n",
    "                                   nr_B_train_imgs=nr_B_train_imgs, # None\n",
    "                                   nr_A_test_imgs=nr_A_test_imgs, # None\n",
    "                                   nr_B_test_imgs=nr_B_test_imgs, # None\n",
    "                                   project_dir=self.project_dir, # '.'\n",
    "                                   subfolder=image_folder) # 'white2stripe'\n",
    "\n",
    "        self.A_train = data[\"trainA_images\"]\n",
    "        self.B_train = data[\"trainB_images\"]\n",
    "        self.A_test = data[\"testA_images\"]\n",
    "        self.B_test = data[\"testB_images\"]\n",
    "        self.testA_image_names = data[\"testA_image_names\"]\n",
    "        self.testB_image_names = data[\"testB_image_names\"]\n",
    "        if not self.use_data_generator:\n",
    "            print('Data has been loaded')\n",
    "\n",
    "        # ======= Create designated run folder and store meta data ==========\n",
    "        directory = os.path.join(self.project_dir, 'images', self.date_time) # images\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        self.writeMetaDataToJSON()\n",
    "\n",
    "        # ======= Avoid pre-allocating GPU memory ==========\n",
    "        # TensorFlow wizardry\n",
    "        config = tf.ConfigProto()\n",
    "\n",
    "        # Don't pre-allocate memory; allocate as-needed\n",
    "        config.gpu_options.allow_growth = True\n",
    "\n",
    "        # Create a session with the above options specified.\n",
    "        K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "        # ===== Tests ======\n",
    "        # Simple Model\n",
    "#         self.G_A2B = self.modelSimple('simple_T1_2_T2_model')\n",
    "#         self.G_B2A = self.modelSimple('simple_T2_2_T1_model')\n",
    "#         self.G_A2B.compile(optimizer=Adam(), loss='MAE')\n",
    "#         self.G_B2A.compile(optimizer=Adam(), loss='MAE')\n",
    "#         # self.trainSimpleModel()\n",
    "#         self.load_model_and_generate_synthetic_images()\n",
    "\n",
    "        # ======= Initialize training ==========\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if self.to_restore:\n",
    "            self.load_latest_weights(self.D_A)\n",
    "            self.load_latest_weights(self.D_B)\n",
    "            self.load_latest_weights(self.G_A2B)\n",
    "            self.load_latest_weights(self.G_B2A)\n",
    "            print(\"Latest model weights have been restored.\")\n",
    "        \n",
    "        # plot model structure\n",
    "        structure_dir = os.path.join(self.project_dir, 'structures')\n",
    "        if not os.path.exists(structure_dir):\n",
    "            os.makedirs(structure_dir)\n",
    "        plot_model(self.D_A, to_file= structure_dir + '/D_A_expanded_model_new.png', show_shapes=True)\n",
    "        plot_model(self.D_B, to_file= structure_dir + '/D_B_expanded_model_new.png', show_shapes=True)\n",
    "        plot_model(self.G_A2B, to_file= structure_dir + '/G_A2B_expanded_model_new.png', show_shapes=True)\n",
    "        plot_model(self.G_B2A, to_file= structure_dir + '/G_B2A_expanded_model_new.png', show_shapes=True)\n",
    "        \n",
    "        if self.to_train:\n",
    "            self.train(epochs=self.epochs, batch_size=self.batch_size, save_interval=self.save_interval)\n",
    "        else:\n",
    "            self.load_model_and_generate_synthetic_images()\n",
    "\n",
    "#===============================================================================\n",
    "# Architecture functions\n",
    "\n",
    "    def ck(self, x, k, use_normalization):\n",
    "        x = Conv2D(filters=k, kernel_size=4, strides=2, padding='same')(x)\n",
    "        # Normalization is not done on the first discriminator layer\n",
    "        if use_normalization:\n",
    "            x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        return x\n",
    "\n",
    "    def c7Ak(self, x, k):\n",
    "        x = Conv2D(filters=k, kernel_size=7, strides=1, padding='valid')(x)\n",
    "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def dk(self, x, k):\n",
    "        x = Conv2D(filters=k, kernel_size=3, strides=2, padding='same')(x)\n",
    "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def Rk(self, x0):\n",
    "        k = int(x0.shape[-1])\n",
    "        # first layer\n",
    "        x = ReflectionPadding2D((1,1))(x0)\n",
    "        x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid')(x)\n",
    "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "        x = Activation('relu')(x)\n",
    "        # second layer\n",
    "        x = ReflectionPadding2D((1, 1))(x)\n",
    "        x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid')(x)\n",
    "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "        # merge\n",
    "        x = add([x, x0])\n",
    "        return x\n",
    "\n",
    "    def uk(self, x, k):\n",
    "        # (up sampling followed by 1x1 convolution <=> fractional-strided 1/2)\n",
    "        if self.use_resize_convolution:\n",
    "            x = UpSampling2D(size=(2, 2))(x)  # Nearest neighbor upsampling\n",
    "            x = ReflectionPadding2D((1, 1))(x)\n",
    "            x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid')(x)\n",
    "        else:\n",
    "            x = Conv2DTranspose(filters=k, kernel_size=3, strides=2, padding='same')(x)  # this matches fractinoally stided with stride 1/2\n",
    "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True) # for channel\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "#===============================================================================\n",
    "# Models\n",
    "\n",
    "    def modelDiscriminator(self, name=None):\n",
    "        # Specify input\n",
    "        input_img = Input(shape=self.img_shape)\n",
    "        # Layer 1 (#Instance normalization is not used for this layer)\n",
    "        x = self.ck(input_img, 64, False)\n",
    "        # Layer 2\n",
    "        x = self.ck(x, 128, True)\n",
    "        # Layer 3\n",
    "        x = self.ck(x, 256, True)\n",
    "        # Layer 4\n",
    "        x = self.ck(x, 512, True)\n",
    "        # Output layer\n",
    "        if self.use_patchgan:\n",
    "            x = Conv2D(filters=1, kernel_size=4, strides=1, padding='same')(x)\n",
    "        else:\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(1)(x)\n",
    "        x = Activation('sigmoid')(x)\n",
    "        return Model(inputs=input_img, outputs=x, name=name)\n",
    "\n",
    "    def modelGenerator(self, name=None):\n",
    "        # Specify input\n",
    "        input_img = Input(shape=self.img_shape)\n",
    "        # Layer 1\n",
    "        x = ReflectionPadding2D((3, 3))(input_img)\n",
    "        x = self.c7Ak(x, 32)\n",
    "        # Layer 2\n",
    "        x = self.dk(x, 64)\n",
    "        # Layer 3\n",
    "        x = self.dk(x, 128)\n",
    "\n",
    "        # Layer 4-12: Residual layer\n",
    "        for _ in range(4, 13):\n",
    "            x = self.Rk(x)\n",
    "\n",
    "        # Layer 13\n",
    "        x = self.uk(x, 64)\n",
    "        # Layer 14\n",
    "        x = self.uk(x, 32)\n",
    "        x = ReflectionPadding2D((3, 3))(x)\n",
    "        x = Conv2D(self.channels, kernel_size=7, strides=1)(x)\n",
    "        x = Activation('tanh')(x)  # They say they use Relu but really they do not\n",
    "        return Model(inputs=input_img, outputs=x, name=name)\n",
    "\n",
    "#===============================================================================\n",
    "# Test - simple model\n",
    "    def modelSimple(self, name=None):\n",
    "        inputImg = Input(shape=self.img_shape)\n",
    "        #x = Conv2D(1, kernel_size=5, strides=1, padding='same')(inputImg)\n",
    "        #x = Dense(self.channels)(x)\n",
    "        x = Conv2D(256, kernel_size=1, strides=1, padding='same')(inputImg)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(self.channels, kernel_size=1, strides=1, padding='same')(x)\n",
    "\n",
    "        return Model(input=inputImg, output=x, name=name)\n",
    "\n",
    "    def trainSimpleModel(self):\n",
    "        real_A = self.A_test[0]\n",
    "        real_B = self.B_test[0]\n",
    "        real_A = real_A[np.newaxis, :, :, :]\n",
    "        real_B = real_B[np.newaxis, :, :, :]\n",
    "        epochs = 200\n",
    "        for epoch in range(epochs):\n",
    "            print('Epoch {} started'.format(epoch))\n",
    "            self.G_A2B.fit(x=self.A_train, y=self.B_train, epochs=1, batch_size=1)\n",
    "            self.G_B2A.fit(x=self.B_train, y=self.A_train, epochs=1, batch_size=1)\n",
    "            #loss = self.G_A2B.train_on_batch(x=real_A, y=real_B)\n",
    "            #print('loss: ', loss)\n",
    "            synthetic_image_A = self.G_B2A.predict(real_B, batch_size=1)\n",
    "            synthetic_image_B = self.G_A2B.predict(real_A, batch_size=1)\n",
    "            self.save_tmp_images(real_A, real_B, synthetic_image_A, synthetic_image_B)\n",
    "\n",
    "        self.saveModel(self.G_A2B, 200)\n",
    "        self.saveModel(self.G_B2A, 200)\n",
    "\n",
    "#===============================================================================\n",
    "# Training\n",
    "    def train(self, epochs, batch_size=1, save_interval=1):\n",
    "        def run_training_iteration(loop_index, epoch_iterations):\n",
    "            # ======= Discriminator training ==========\n",
    "                # Generate batch of synthetic images\n",
    "            synthetic_images_B = self.G_A2B.predict(real_images_A)\n",
    "            synthetic_images_A = self.G_B2A.predict(real_images_B)\n",
    "            synthetic_images_A = synthetic_pool_A.query(synthetic_images_A)\n",
    "            synthetic_images_B = synthetic_pool_B.query(synthetic_images_B)\n",
    "\n",
    "            for _ in range(self.discriminator_iterations):\n",
    "                DA_loss_real = self.D_A.train_on_batch(x=real_images_A, y=ones)\n",
    "                DB_loss_real = self.D_B.train_on_batch(x=real_images_B, y=ones)\n",
    "                DA_loss_synthetic = self.D_A.train_on_batch(x=synthetic_images_A, y=zeros)\n",
    "                DB_loss_synthetic = self.D_B.train_on_batch(x=synthetic_images_B, y=zeros)\n",
    "\n",
    "                DA_loss = DA_loss_real + DA_loss_synthetic\n",
    "                DB_loss = DB_loss_real + DB_loss_synthetic\n",
    "                D_loss = DA_loss + DB_loss\n",
    "\n",
    "                if self.discriminator_iterations > 1:\n",
    "                    print('D_loss:', D_loss)\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            # ======= Generator training ==========\n",
    "            target_data = [real_images_A, real_images_B]  # Compare reconstructed images to real images\n",
    "            target_data.append(ones)\n",
    "            target_data.append(ones)\n",
    "\n",
    "            if self.use_supervised_learning:\n",
    "                target_data.append(real_images_A)\n",
    "                target_data.append(real_images_B)\n",
    "\n",
    "            for _ in range(self.generator_iterations):\n",
    "                G_loss = self.G_model.train_on_batch(\n",
    "                    x=[real_images_A, real_images_B], y=target_data)\n",
    "                if self.generator_iterations > 1:\n",
    "                    print('G_loss:', G_loss)\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            gA_d_loss_synthetic = G_loss[1]\n",
    "            gB_d_loss_synthetic = G_loss[2]\n",
    "            reconstruction_loss_A = G_loss[3]\n",
    "            reconstruction_loss_B = G_loss[4]\n",
    "\n",
    "            # Identity training\n",
    "            if self.use_identity_learning and loop_index % self.identity_mapping_modulus == 0:\n",
    "                G_A2B_identity_loss = self.G_A2B.train_on_batch(\n",
    "                    x=real_images_B, y=real_images_B)\n",
    "                G_B2A_identity_loss = self.G_B2A.train_on_batch(\n",
    "                    x=real_images_A, y=real_images_A)\n",
    "                print('G_A2B_identity_loss:', G_A2B_identity_loss)\n",
    "                print('G_B2A_identity_loss:', G_B2A_identity_loss)\n",
    "\n",
    "            # Update learning rates\n",
    "            if self.use_linear_decay and epoch > self.decay_epoch:\n",
    "                self.update_lr(self.D_A, decay_D)\n",
    "                self.update_lr(self.D_B, decay_D)\n",
    "                self.update_lr(self.G_model, decay_G)\n",
    "\n",
    "            # Store training data\n",
    "            DA_losses.append(DA_loss)\n",
    "            DB_losses.append(DB_loss)\n",
    "            gA_d_losses_synthetic.append(gA_d_loss_synthetic)\n",
    "            gB_d_losses_synthetic.append(gB_d_loss_synthetic)\n",
    "            gA_losses_reconstructed.append(reconstruction_loss_A)\n",
    "            gB_losses_reconstructed.append(reconstruction_loss_B)\n",
    "\n",
    "            GA_loss = gA_d_loss_synthetic + reconstruction_loss_A\n",
    "            GB_loss = gB_d_loss_synthetic + reconstruction_loss_B\n",
    "            D_losses.append(D_loss)\n",
    "            GA_losses.append(GA_loss)\n",
    "            GB_losses.append(GB_loss)\n",
    "            G_losses.append(G_loss)\n",
    "            reconstruction_loss = reconstruction_loss_A + reconstruction_loss_B\n",
    "            reconstruction_losses.append(reconstruction_loss)\n",
    "\n",
    "            print('\\n')\n",
    "            print('Epoch----------------', epoch, '/', epochs)\n",
    "            print('Loop index----------------', loop_index + 1, '/', epoch_iterations)\n",
    "            print('D_loss: ', D_loss)\n",
    "            print('G_loss: ', G_loss[0])\n",
    "            print('reconstruction_loss: ', reconstruction_loss)\n",
    "            print('dA_loss:', DA_loss)\n",
    "            print('DB_loss:', DB_loss)\n",
    "\n",
    "            if loop_index % 20 == 0:\n",
    "                # Save temporary images continously\n",
    "                self.save_tmp_images(real_images_A, real_images_B, synthetic_images_A, synthetic_images_B)\n",
    "                self.print_ETA(start_time, epoch, epoch_iterations, loop_index)\n",
    "\n",
    "        # ======================================================================\n",
    "        # Begin training\n",
    "        # ======================================================================\n",
    "        training_history = OrderedDict()\n",
    "\n",
    "        DA_losses = []\n",
    "        DB_losses = []\n",
    "        gA_d_losses_synthetic = []\n",
    "        gB_d_losses_synthetic = []\n",
    "        gA_losses_reconstructed = []\n",
    "        gB_losses_reconstructed = []\n",
    "\n",
    "        GA_losses = []\n",
    "        GB_losses = []\n",
    "        reconstruction_losses = []\n",
    "        D_losses = []\n",
    "        G_losses = []\n",
    "\n",
    "        # Image pools used to update the discriminators\n",
    "        synthetic_pool_A = ImagePool(self.synthetic_pool_size)\n",
    "        synthetic_pool_B = ImagePool(self.synthetic_pool_size)\n",
    "\n",
    "        # self.saveImages('(init)')\n",
    "\n",
    "        # labels\n",
    "        label_shape = (batch_size,) + self.D_A.output_shape[1:]\n",
    "        ones = np.ones(shape=label_shape) * self.REAL_LABEL\n",
    "        zeros = ones * 0\n",
    "\n",
    "        # Linear decay\n",
    "        if self.use_linear_decay:\n",
    "            decay_D, decay_G = self.get_lr_linear_decay_rate()\n",
    "\n",
    "        # Start stopwatch for ETAs\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            if self.use_data_generator:\n",
    "                loop_index = 1\n",
    "                for images in self.data_generator:\n",
    "                    real_images_A = images[0]\n",
    "                    real_images_B = images[1]\n",
    "                    if len(real_images_A.shape) == 3:\n",
    "                        real_images_A = real_images_A[:, :, :, np.newaxis]\n",
    "                        real_images_B = real_images_B[:, :, :, np.newaxis]\n",
    "\n",
    "                    # Run all training steps\n",
    "                    run_training_iteration(loop_index, self.data_generator.__len__())\n",
    "\n",
    "                    # Store models\n",
    "                    if loop_index % 20000 == 0:\n",
    "                        self.saveModel(self.D_A, loop_index)\n",
    "                        self.saveModel(self.D_B, loop_index)\n",
    "                        self.saveModel(self.G_A2B, loop_index)\n",
    "                        self.saveModel(self.G_B2A, loop_index)\n",
    "\n",
    "                    # Break if loop has ended\n",
    "                    if loop_index >= self.data_generator.__len__():\n",
    "                        break\n",
    "\n",
    "                    loop_index += 1\n",
    "\n",
    "            else:  # Train with all data in cache\n",
    "                A_train = self.A_train\n",
    "                B_train = self.B_train\n",
    "                random_order_A = np.random.randint(len(A_train), size=len(A_train))\n",
    "                random_order_B = np.random.randint(len(B_train), size=len(B_train))\n",
    "                epoch_iterations = max(len(random_order_A), len(random_order_B))\n",
    "                min_nr_imgs = min(len(random_order_A), len(random_order_B))\n",
    "\n",
    "                # If we want supervised learning the same images form\n",
    "                # the two domains are needed during each training iteration\n",
    "                if self.use_supervised_learning:\n",
    "                    random_order_B = random_order_A\n",
    "                for loop_index in range(0, epoch_iterations, batch_size): # loop index = total images / batch_size\n",
    "                    if loop_index + batch_size >= min_nr_imgs:\n",
    "                        # If all images soon are used for one domain,\n",
    "                        # randomly pick from this domain\n",
    "                        if len(A_train) <= len(B_train):\n",
    "                            indexes_A = np.random.randint(len(A_train), size=batch_size)\n",
    "                            indexes_B = random_order_B[loop_index:\n",
    "                                                       loop_index + batch_size]\n",
    "                        else:\n",
    "                            indexes_B = np.random.randint(len(B_train), size=batch_size)\n",
    "                            indexes_A = random_order_A[loop_index:\n",
    "                                                       loop_index + batch_size]\n",
    "                    else:\n",
    "                        indexes_A = random_order_A[loop_index:\n",
    "                                                   loop_index + batch_size] # get image array of batch size\n",
    "                        indexes_B = random_order_B[loop_index:\n",
    "                                                   loop_index + batch_size]\n",
    "\n",
    "                    sys.stdout.flush()\n",
    "                    real_images_A = A_train[indexes_A]\n",
    "                    real_images_B = B_train[indexes_B]\n",
    "\n",
    "                    # Run all training steps\n",
    "                    run_training_iteration(loop_index, epoch_iterations)\n",
    "\n",
    "            #================== within epoch loop end ==========================\n",
    "\n",
    "            if epoch % save_interval == 0:\n",
    "                print('\\n', '\\n', '-------------------------Saving images for epoch', epoch, '-------------------------', '\\n', '\\n')\n",
    "                self.saveImages(epoch, real_images_A, real_images_B)\n",
    "\n",
    "            if epoch % 20 == 0:\n",
    "                # self.saveModel(self.G_model)\n",
    "                self.saveModel(self.D_A, epoch)\n",
    "                self.saveModel(self.D_B, epoch)\n",
    "                self.saveModel(self.G_A2B, epoch)\n",
    "                self.saveModel(self.G_B2A, epoch)\n",
    "\n",
    "            training_history = {\n",
    "                'DA_losses': DA_losses,\n",
    "                'DB_losses': DB_losses,\n",
    "                'gA_d_losses_synthetic': gA_d_losses_synthetic,\n",
    "                'gB_d_losses_synthetic': gB_d_losses_synthetic,\n",
    "                'gA_losses_reconstructed': gA_losses_reconstructed,\n",
    "                'gB_losses_reconstructed': gB_losses_reconstructed,\n",
    "                'D_losses': D_losses,\n",
    "                'G_losses': G_losses,\n",
    "                'reconstruction_losses': reconstruction_losses}\n",
    "            self.writeLossDataToFile(training_history)\n",
    "\n",
    "            # Flush out prints each loop iteration\n",
    "            sys.stdout.flush()\n",
    "\n",
    "#===============================================================================\n",
    "# Help functions\n",
    "\n",
    "    def lse(self, y_true, y_pred):\n",
    "        loss = tf.reduce_mean(tf.squared_difference(y_pred, y_true))\n",
    "        return loss\n",
    "\n",
    "    def cycle_loss(self, y_true, y_pred):\n",
    "        loss = tf.reduce_mean(tf.abs(y_pred - y_true))\n",
    "        return loss\n",
    "\n",
    "    def truncateAndSave(self, real_, real, synthetic, reconstructed, path_name):\n",
    "        if len(real.shape) > 3:\n",
    "            real = real[0]\n",
    "            synthetic = synthetic[0]\n",
    "            reconstructed = reconstructed[0]\n",
    "\n",
    "        # Append and save\n",
    "        if real_ is not None:\n",
    "            if len(real_.shape) > 4:\n",
    "                real_ = real_[0]\n",
    "            image = np.hstack((real_[0], real, synthetic, reconstructed))\n",
    "        else:\n",
    "            image = np.hstack((real, synthetic, reconstructed))\n",
    "\n",
    "        if self.channels == 1:\n",
    "            image = image[:, :, 0]\n",
    "\n",
    "        toimage(image, cmin=-1, cmax=1).save(path_name) # deprecated\n",
    "#         image = Image.fromarray(image, 'RGB')\n",
    "#         image.save(path_name)\n",
    "\n",
    "    def saveImages(self, epoch, real_image_A, real_image_B, num_saved_images=1):\n",
    "        directory = os.path.join(self.project_dir, 'images', self.date_time)\n",
    "        if not os.path.exists(os.path.join(directory, 'A')):\n",
    "            os.makedirs(os.path.join(directory, 'A'))\n",
    "            os.makedirs(os.path.join(directory, 'B'))\n",
    "            os.makedirs(os.path.join(directory, 'Atest'))\n",
    "            os.makedirs(os.path.join(directory, 'Btest'))\n",
    "\n",
    "        testString = ''\n",
    "\n",
    "        real_image_Ab = None\n",
    "        real_image_Ba = None\n",
    "        for i in range(num_saved_images + 1):\n",
    "            if i == num_saved_images:\n",
    "                real_image_A = self.A_test[0]\n",
    "                real_image_B = self.B_test[0]\n",
    "                real_image_A = np.expand_dims(real_image_A, axis=0)\n",
    "                real_image_B = np.expand_dims(real_image_B, axis=0)\n",
    "                testString = 'test'\n",
    "                \n",
    "            else:\n",
    "                #real_image_A = self.A_train[rand_A_idx[i]]\n",
    "                #real_image_B = self.B_train[rand_B_idx[i]]\n",
    "                if len(real_image_A.shape) < 4:\n",
    "                    real_image_A = np.expand_dims(real_image_A, axis=0)\n",
    "                    real_image_B = np.expand_dims(real_image_B, axis=0)\n",
    "                \n",
    "            synthetic_image_B = self.G_A2B.predict(real_image_A)\n",
    "            synthetic_image_A = self.G_B2A.predict(real_image_B)\n",
    "            reconstructed_image_A = self.G_B2A.predict(synthetic_image_B)\n",
    "            reconstructed_image_B = self.G_A2B.predict(synthetic_image_A)\n",
    "\n",
    "            self.truncateAndSave(real_image_Ab, real_image_A, synthetic_image_B, reconstructed_image_A,\n",
    "                                 self.project_dir + '/images/{}/{}/epoch{}_sample{}.png'.format(\n",
    "                                     self.date_time, 'A' + testString, epoch, i))\n",
    "            self.truncateAndSave(real_image_Ba, real_image_B, synthetic_image_A, reconstructed_image_B,\n",
    "                                 self.project_dir + '/images/{}/{}/epoch{}_sample{}.png'.format(\n",
    "                                     self.date_time, 'B' + testString, epoch, i))\n",
    "\n",
    "    def save_tmp_images(self, real_image_A, real_image_B, synthetic_image_A, synthetic_image_B):\n",
    "        try:\n",
    "            reconstructed_image_A = self.G_B2A.predict(synthetic_image_B)\n",
    "            reconstructed_image_B = self.G_A2B.predict(synthetic_image_A)\n",
    "\n",
    "            real_images = np.vstack((real_image_A[0], real_image_B[0]))\n",
    "            synthetic_images = np.vstack((synthetic_image_B[0], synthetic_image_A[0]))\n",
    "            reconstructed_images = np.vstack((reconstructed_image_A[0], reconstructed_image_B[0]))\n",
    "\n",
    "            self.truncateAndSave(None, real_images, synthetic_images, reconstructed_images,\n",
    "                                 self.project_dir + '/images/{}/{}.png'.format(\n",
    "                                     self.date_time, 'tmp'))\n",
    "        except: # Ignore if file is open\n",
    "            pass\n",
    "\n",
    "    def get_lr_linear_decay_rate(self):\n",
    "        # Calculate decay rates\n",
    "        if self.use_data_generator:\n",
    "            max_nr_images = len(self.data_generator)\n",
    "        else:\n",
    "            max_nr_images = max(len(self.A_train), len(self.B_train))\n",
    "\n",
    "        updates_per_epoch_D = 2 * max_nr_images + self.discriminator_iterations - 1\n",
    "        updates_per_epoch_G = max_nr_images + self.generator_iterations - 1\n",
    "        if self.use_identity_learning:\n",
    "            updates_per_epoch_G *= (1 + 1 / self.identity_mapping_modulus)\n",
    "        denominator_D = (self.epochs - self.decay_epoch) * updates_per_epoch_D\n",
    "        denominator_G = (self.epochs - self.decay_epoch) * updates_per_epoch_G\n",
    "        decay_D = self.learning_rate_D / denominator_D\n",
    "        decay_G = self.learning_rate_G / denominator_G\n",
    "\n",
    "        return decay_D, decay_G\n",
    "\n",
    "    def update_lr(self, model, decay):\n",
    "        new_lr = K.get_value(model.optimizer.lr) - decay\n",
    "        if new_lr < 0:\n",
    "            new_lr = 0\n",
    "        # print(K.get_value(model.optimizer.lr))\n",
    "        K.set_value(model.optimizer.lr, new_lr)\n",
    "\n",
    "    def print_ETA(self, start_time, epoch, epoch_iterations, loop_index):\n",
    "        passed_time = time.time() - start_time\n",
    "\n",
    "        iterations_so_far = ((epoch - 1) * epoch_iterations + loop_index) / self.batch_size\n",
    "        iterations_total = self.epochs * epoch_iterations / self.batch_size\n",
    "        iterations_left = iterations_total - iterations_so_far\n",
    "        eta = round(passed_time / (iterations_so_far + 1e-5) * iterations_left)\n",
    "\n",
    "        passed_time_string = str(datetime.timedelta(seconds=round(passed_time)))\n",
    "        eta_string = str(datetime.timedelta(seconds=eta))\n",
    "        print('Time passed', passed_time_string, ': ETA in', eta_string)\n",
    "\n",
    "\n",
    "#===============================================================================\n",
    "# Save and load\n",
    "\n",
    "    def saveModel(self, model, epoch):\n",
    "        # Create folder to save model architecture and weights\n",
    "        directory = os.path.join(self.project_dir, 'saved_models', self.date_time)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        model_path_w = self.project_dir + '/saved_models/{}/{}_weights_epoch_{}.hdf5'.format(self.date_time, model.name, epoch)\n",
    "        model.save_weights(model_path_w)\n",
    "        model_path_m = self.project_dir + '/saved_models/{}/{}_model_epoch_{}.json'.format(self.date_time, model.name, epoch)\n",
    "        model.save_weights(model_path_m)\n",
    "        json_string = model.to_json()\n",
    "        with open(model_path_m, 'w') as outfile:\n",
    "            json.dump(json_string, outfile)\n",
    "        print('{} has been saved in /saved_models/{}/'.format(model.name, self.date_time))\n",
    "\n",
    "    def writeLossDataToFile(self, history):\n",
    "        keys = sorted(history.keys())\n",
    "        with open(self.project_dir + '/images/{}/loss_output.csv'.format(self.date_time), 'w+') as csv_file:\n",
    "            writer = csv.writer(csv_file, delimiter=',')\n",
    "            writer.writerow(keys)\n",
    "            writer.writerows(zip(*[history[key] for key in keys]))\n",
    "\n",
    "    def writeMetaDataToJSON(self):\n",
    "\n",
    "        directory = os.path.join(self.project_dir, 'images', self.date_time)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        # Save meta_data\n",
    "        data = {}\n",
    "        data['meta_data'] = []\n",
    "        data['meta_data'].append({\n",
    "            'img shape: height,width,channels': self.img_shape,\n",
    "            'batch size': self.batch_size,\n",
    "            'save interval': self.save_interval,\n",
    "            'normalization function': str(self.normalization),\n",
    "            'lambda_1': self.lambda_1,\n",
    "            'lambda_2': self.lambda_2,\n",
    "            'lambda_d': self.lambda_D,\n",
    "            'learning_rate_D': self.learning_rate_D,\n",
    "            'learning rate G': self.learning_rate_G,\n",
    "            'epochs': self.epochs,\n",
    "            'use linear decay on learning rates': self.use_linear_decay,\n",
    "            'epoch where learning rate linear decay is initialized (if use_linear_decay)': self.decay_epoch,\n",
    "            'generator iterations': self.generator_iterations,\n",
    "            'discriminator iterations': self.discriminator_iterations,\n",
    "            'use patchGan in discriminator': self.use_patchgan,\n",
    "            'beta 1': self.beta_1,\n",
    "            'beta 2': self.beta_2,\n",
    "            'REAL_LABEL': self.REAL_LABEL,\n",
    "            'number of A train examples': len(self.A_train),\n",
    "            'number of B train examples': len(self.B_train),\n",
    "            'number of A test examples': len(self.A_test),\n",
    "            'number of B test examples': len(self.B_test),\n",
    "        })\n",
    "\n",
    "        with open(self.project_dir + '/images/{}/meta_data.json'.format(self.date_time), 'w+') as outfile:\n",
    "            json.dump(data, outfile, sort_keys=True)\n",
    "\n",
    "    def load_latest_weights(self, model): # /saved_models/{self.date_time}/{model.name}_weights_epoch_{epoch}.hdf5\n",
    "        models = sorted(os.listdir(os.path.join(self.project_dir, 'saved_models')))\n",
    "        latest_model = os.path.join(self.project_dir, 'saved_models', models[-1])\n",
    "\n",
    "        epochs = sorted([ep.split(\"_\")[-1] for ep in os.listdir(latest_model)])\n",
    "        latest_epoch = epochs[-1].split('.')[0] # 40.json ;;\n",
    "\n",
    "        # path_to_model = os.path.join(latest_model, '{}_model_epoch_{}.json'.format(mode.name, latest_epoch))\n",
    "        path_to_weights = os.path.join(latest_model, '{}_weights_epoch_{}.hdf5'.format(model.name, latest_epoch))\n",
    "        # model = model_from_json(path_to_model)\n",
    "        \n",
    "        print(f\"loading {str(model.name)} model weights from {str(path_to_weights)}...\")\n",
    "        model.load_weights(path_to_weights)\n",
    "\n",
    "    def load_model_and_weights(self, model):\n",
    "        # you should copy most well-trained model from /saved_models to /generate_images/models\n",
    "        path_to_model = os.path.join(self.project_dir, 'generate_images', 'models', '{}.json'.format(model.name))\n",
    "        path_to_weights = os.path.join(self.project_dir, 'generate_images', 'models', '{}.hdf5'.format(model.name))\n",
    "        #model = model_from_json(path_to_model)\n",
    "        \n",
    "        print(f\"loading {str(model.name)} model weights from {str(path_to_weights)}...\")\n",
    "        model.load_weights(path_to_weights)\n",
    "\n",
    "    def load_model_and_generate_synthetic_images(self):\n",
    "        # response = input('Are you sure you want to generate synthetic images instead of training? (y/n): ')[0].lower()\n",
    "        # if response == 'y':\n",
    "        self.load_model_and_weights(self.G_A2B)\n",
    "        self.load_model_and_weights(self.G_B2A)\n",
    "        synthetic_images_B = self.G_A2B.predict(self.A_test)\n",
    "        synthetic_images_A = self.G_B2A.predict(self.B_test)\n",
    "\n",
    "        def save_image(image, name, domain):\n",
    "            if self.channels == 1:\n",
    "                image = image[:, :, 0]\n",
    "            toimage(image, cmin=-1, cmax=1).save(os.path.join(\n",
    "                self.project_dir, 'generate_images', 'synthetic_images', domain, name)) # deprecated\n",
    "#             image = Image.fromarray(image, 'RGB')\n",
    "#             image.save(os.path.join(\n",
    "#                 self.project_dir, 'generate_images', 'synthetic_images', domain, name))\n",
    "\n",
    "        # Test A images\n",
    "        for i in range(len(synthetic_images_A)):\n",
    "            # Get the name from the image it was conditioned on\n",
    "            name = self.testB_image_names[i].strip('.png') + '_synthetic.png'\n",
    "            synt_A = synthetic_images_A[i]\n",
    "            save_image(synt_A, name, 'A')\n",
    "\n",
    "        # Test B images\n",
    "        for i in range(len(synthetic_images_B)):\n",
    "            # Get the name from the image it was conditioned on\n",
    "            name = self.testA_image_names[i].strip('.png') + '_synthetic.png'\n",
    "            synt_B = synthetic_images_B[i]\n",
    "            save_image(synt_B, name, 'B')\n",
    "\n",
    "        print('{} synthetic images have been generated and placed in ./generate_images/synthetic_images'\n",
    "                .format(len(self.A_test) + len(self.B_test)))\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad, h_pad = self.padding\n",
    "        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
    "\n",
    "\n",
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            if len(image.shape) == 3:\n",
    "                image = image[np.newaxis, :, :, :]\n",
    "\n",
    "            if self.num_imgs < self.pool_size:  # fill up the image pool\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                if len(self.images) == 0:\n",
    "                    self.images = image\n",
    "                else:\n",
    "                    self.images = np.vstack((self.images, image))\n",
    "\n",
    "                if len(return_images) == 0:\n",
    "                    return_images = image\n",
    "                else:\n",
    "                    return_images = np.vstack((return_images, image))\n",
    "\n",
    "            else:  # 50% chance that we replace an old synthetic image\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.images[random_id, :, :, :]\n",
    "                    tmp = tmp[np.newaxis, :, :, :]\n",
    "                    self.images[random_id, :, :, :] = image[0, :, :, :]\n",
    "                    if len(return_images) == 0:\n",
    "                        return_images = tmp\n",
    "                    else:\n",
    "                        return_images = np.vstack((return_images, tmp))\n",
    "                else:\n",
    "                    if len(return_images) == 0:\n",
    "                        return_images = image\n",
    "                    else:\n",
    "                        return_images = np.vstack((return_images, image))\n",
    "\n",
    "        return return_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()\n",
    "\n",
    "**Class arguments**\n",
    "\n",
    "- `lr_D`=2e-4\n",
    "\n",
    "- `lr_G`=2e-4\n",
    "\n",
    "- `image_shape`=(256 * 1, 256 * 1, 3)\n",
    "                 \n",
    "- `date_time_string_addition`='_test'\n",
    "\n",
    "- `project_dir`='.'\n",
    "\n",
    "- `image_folder`=''\n",
    "\n",
    "- `to_train`=True\n",
    "\n",
    "- `to_restore`=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    GAN = CycleGAN(project_dir = '.', image_folder='white2stripe', to_train=True, to_restore=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
